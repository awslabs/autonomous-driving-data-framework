{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37954e43",
   "metadata": {},
   "source": [
    "# Run Experimental Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012cc99",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861feb0",
   "metadata": {},
   "source": [
    "#### Update Sagemaker and AWS CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e47480",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82355ef9",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8194d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    ")\n",
    "from sagemaker.workflow.functions import (\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(\"\")\n",
    "\n",
    "\n",
    "def get_sagemaker_client(region):\n",
    "    \"\"\"Gets the sagemaker client.\n",
    "\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    return sagemaker_client\n",
    "\n",
    "\n",
    "def get_session(region, default_bucket):\n",
    "    \"\"\"Gets the sagemaker session based on the region.\n",
    "\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        `sagemaker.session.Session instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "    runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "    return sagemaker.session.Session(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        sagemaker_runtime_client=runtime_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_pipeline_session(region, default_bucket):\n",
    "    \"\"\"Gets the pipeline session based on the region.\n",
    "\n",
    "    Args:\n",
    "        region: the aws region to start the session\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "\n",
    "    Returns:\n",
    "        PipelineSession instance\n",
    "    \"\"\"\n",
    "\n",
    "    boto_session = boto3.Session(region_name=region)\n",
    "    sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "\n",
    "    return PipelineSession(\n",
    "        boto_session=boto_session,\n",
    "        sagemaker_client=sagemaker_client,\n",
    "        default_bucket=default_bucket,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_pipeline_custom_tags(new_tags, region, sagemaker_project_arn=None):\n",
    "    try:\n",
    "        sm_client = get_sagemaker_client(region)\n",
    "        response = sm_client.list_tags(ResourceArn=sagemaker_project_arn)\n",
    "        project_tags = response[\"Tags\"]\n",
    "        for project_tag in project_tags:\n",
    "            new_tags.append(project_tag)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting project tags: {e}\")\n",
    "    return new_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd6e06",
   "metadata": {},
   "source": [
    "# Sagemaker Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c993b25",
   "metadata": {},
   "source": [
    "#### [General Overview](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-sdk.html)\n",
    "\n",
    "#### In-short:  A SageMaker pipeline is a series of interconnected steps used to describe and enable a concrete workflow. \n",
    "\n",
    "This pipeline definition encodes a pipeline using a directed acyclic graph (DAG) that can be exported as a JSON definition. This DAG gives information on the requirements for and relationships between each step of your pipeline. The structure of a pipeline's DAG is determined by the data dependencies between steps. These data dependencies are created when the properties of a step's output are passed as the input to another step. \n",
    "\n",
    "SageMaker Pipelines are composed of *steps*. These steps define the actions that the pipeline takes and the relationships between steps using properties.\n",
    "\n",
    "#### [Step Types: ](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html)\n",
    "The following describes the requirements of each step type and provides an example implementation of the step. These are not functional implementations because they don't provide the resource and inputs needed. For a tutorial that implements these steps, see Create and Manage SageMaker Pipelines.\n",
    "\n",
    "Amazon SageMaker Model Building Pipelines support the following step types:\n",
    "\n",
    "- *[Processing](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)* (we're using this one for step 1: Data Preprocessing | code: init_cache.py)\n",
    "- *[Training](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-training)* (we're using this one for step 2: training the CNN with Pytorch and capturing metrics of the process | code: train.py, dataset.py, blazeface.py)\n",
    "- *[Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-tuning)* (future optimization: hyperparemeter optimization)\n",
    "- *Model*\n",
    "- *CreateModel*\n",
    "- *[RegisterModel](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-register-model)* (we're using it for registering the model in the model registry)\n",
    "- Transform\n",
    "- Condition\n",
    "- Callback\n",
    "- Lambda\n",
    "- ClarifyCheck\n",
    "- QualityCheck\n",
    "- EMR\n",
    "- Fail \n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"us-east-2\"\n",
    "default_bucket = None\n",
    "role = None\n",
    "processing_instance_type = \"ml.m5.xlarge\"\n",
    "training_instance_type = \"ml.m5.xlarge\"\n",
    "base_job_prefix = \"abalone\"\n",
    "model_package_group_name = \"abalone-pipeline-exp-models\"\n",
    "base_job_prefix = \"abalone\"\n",
    "\n",
    "config_file = open(\"../.sagemaker-code-config\")\n",
    "sagemaker_code_config = json.load(config_file)\n",
    "sagemaker_pipeline_name = sagemaker_code_config[\"sagemakerPipelineName\"]\n",
    "pipeline_name = f\"{sagemaker_pipeline_name}-experimental\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c874f5c",
   "metadata": {},
   "source": [
    "## Pipeline Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = get_session(region, default_bucket)\n",
    "if role is None:\n",
    "    role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "\n",
    "pipeline_session = get_pipeline_session(region, default_bucket)\n",
    "\n",
    "# parameters for pipeline execution\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\", default_value=1\n",
    ")\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputDataUrl\",\n",
    "    default_value=f\"s3://sagemaker-servicecatalog-seedcode-{region}/dataset/abalone-dataset.csv\",\n",
    ")\n",
    "\n",
    "# processing step for feature engineering\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=f\"{base_job_prefix}/sklearn-abalone-preprocess\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "step_args = sklearn_processor.run(\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\", source=\"/opt/ml/processing/validation\"\n",
    "        ),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=os.path.join(BASE_DIR, \"scripts/preprocess.py\"),\n",
    "    arguments=[\"--input-data\", input_data],\n",
    ")\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessAbaloneData\",\n",
    "    step_args=step_args,\n",
    ")\n",
    "\n",
    "# training step for generating model artifacts\n",
    "model_path = f\"s3://{sagemaker_session.default_bucket()}/{base_job_prefix}/AbaloneTrain\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"{base_job_prefix}/abalone-train\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:linear\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    "    silent=0,\n",
    ")\n",
    "step_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainAbaloneModel\",\n",
    "    step_args=step_args,\n",
    ")\n",
    "\n",
    "# processing step for evaluation\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=f\"{base_job_prefix}/script-abalone-eval\",\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "step_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"\n",
    "        ),\n",
    "    ],\n",
    "    code=os.path.join(BASE_DIR, \"scripts/evaluate.py\"),\n",
    ")\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"AbaloneEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateAbaloneModel\",\n",
    "    step_args=step_args,\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "# register model step that will be conditionally executed\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\n",
    "                \"S3Uri\"\n",
    "            ]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "step_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "step_register = ModelStep(\n",
    "    name=\"RegisterAbaloneModel\",\n",
    "    step_args=step_args,\n",
    ")\n",
    "\n",
    "# condition step for evaluating model quality and branching execution\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=6.0,\n",
    ")\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckMSEAbaloneEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register],\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "# pipeline instance\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        training_instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aad7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug  3 2022, 14:53:30) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fd883dd04ff07325021088a4860b95cab45580608d5939ff45c47d285513350"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
